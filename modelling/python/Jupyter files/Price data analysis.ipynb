{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Price data analysis\n",
    "This notebook includes a number of codes to conduct data analysis on the NEM spot prices. The required data for this analysis come from the database files that are ceated by ```Data miner``` codes. This notebook includes the following scripts: <br>\n",
    "\n",
    "1- Graphically compare the forecast and predispatch prices <br>\n",
    "2- Find a list of the days with very high spot prices <br>\n",
    "3- Plot mean squared error for the whole year <br>\n",
    "4- Plot region price vs NEM total demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "print(\"Operating system: %s\" %sys.platform)\n",
    "if sys.platform == 'win32':\n",
    "    curr_path = 'c:\\\\Nextcloud\\\\Thermal Battery Research\\\\modelling\\\\python'\n",
    "elif sys.platform == 'linux':\n",
    "    curr_path = '/home/jeff/cloud/documents/work/ANU/Thermal Battery Research/modelling/python'\n",
    "else: print(\"What operating system are you running?! I've never even heard of %s\" %sys.platform)\n",
    "if curr_path not in sys.path:\n",
    "    sys.path.append(curr_path)\n",
    "    print('Path added! \\n')\n",
    "os.chdir(curr_path)\n",
    "print(\"Working directory is now %s\" %curr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface plot RRP values for the specified region and year\n",
    "This script reads the rrp values from the ```spot_price.db``` database and surfplots their variations over the year for a selected state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "print(\"Operating system: %s\" %sys.platform)\n",
    "if sys.platform == 'win32':\n",
    "    curr_path = 'c:\\\\Nextcloud\\\\Thermal Battery Research\\\\modelling\\\\python'\n",
    "elif sys.platform == 'linux':\n",
    "    curr_path = '/home/jeff/cloud/documents/work/ANU/Thermal Battery Research/modelling/python'\n",
    "else: print(\"What operating system are you running?! I've never even heard of %s\" %sys.platform)\n",
    "if curr_path not in sys.path:\n",
    "    sys.path.append(curr_path)\n",
    "    print('Path added! \\n')\n",
    "os.chdir(curr_path)\n",
    "print(\"Working directory is now %s\" %curr_path)\n",
    "\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import cm, dates\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import package.get_NEM_data as gd\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "# %matplotlib inline\n",
    "\n",
    "# choose the state and date here\n",
    "State='NSW'\n",
    "font_size = 12\n",
    "\n",
    "def f(x,y):\n",
    "    return np.array(data.loc[(datetime.datetime.combine(x, y))]['spot_price'])\n",
    "\n",
    "def ff(x):\n",
    "    return x.hour*60+x.minute\n",
    "\n",
    "for year in np.arange(2010,2019,1):\n",
    "    plt.close(\"all\")\n",
    "    price_spot=pd.DataFrame(gd.load_rrp_cal_stamped(year, State))\n",
    "    \n",
    "\n",
    "    price_spot.columns = ['region', 'date_time', 'spot_price'] # define the data columns \n",
    "    price_spot['date_time'] = pd.to_datetime(price_spot['date_time'])\n",
    "    \n",
    "    data = price_spot.set_index('date_time')\n",
    "    x1 = pd.date_range(data.index.date.min(),\n",
    "                       data.index.date.max(), freq='1D').date\n",
    "    y1 = pd.date_range('00:00:00','23:30:00', freq='30min').time\n",
    "\n",
    "    x2, y2 = np.meshgrid(x1,y1)\n",
    "\n",
    "    g = np.vectorize(f)\n",
    "    gg = np.vectorize(ff)\n",
    "    z = g(x2,y2)\n",
    "    z[z<-50]=-50\n",
    "    z[z>300]=300\n",
    "\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = Axes3D(fig, proj_type = 'ortho')\n",
    "    \n",
    "    surf = ax.plot_surface(dates.date2num(x2), gg(y2), z, rstride=1, cstride = 1,\n",
    "                           edgecolor='k', linewidth=0.2, cmap=cm.jet)\n",
    "\n",
    "    x_tick_range = pd.date_range(data.index.date.min(),\n",
    "                       data.index.date.max(), freq='1D').date\n",
    "\n",
    "    \n",
    "    ax.set_xlim(x_tick_range.min(), x_tick_range.max())\n",
    "    ax.xaxis.set_tick_params(rotation=90 )\n",
    "    \n",
    "    ax.set_zticklabels(ax.axes.get_zticks(), horizontalalignment= 'left')\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "    \n",
    "    ax.axes.set_yticks(np.arange(0,25*60,120))\n",
    "    ax.axes.set_ylim([0,1450])\n",
    "    ytick_range = ax.axes.get_yticks()\n",
    "    m = len(ax.axes.get_yticks())\n",
    "    ylabels = pd.date_range(start = '2000-01-01', end = '2000-01-02',  periods=m)\n",
    "    ylabels = [datetime.datetime.strftime(Label, '%H:%M') for Label in ylabels]\n",
    "    ax.set_yticklabels(ylabels,rotation=-90, va='top', ha='right')\n",
    "    \n",
    "    ax.set_zlabel('RRP [$/MWh]', fontsize=font_size, labelpad=15)\n",
    "    ax.axes.invert_xaxis()\n",
    "    ax.xaxis.set_tick_params(labelsize=font_size)\n",
    "    ax.yaxis.set_tick_params(labelsize=font_size)\n",
    "    ax.zaxis.set_tick_params(labelsize=font_size)\n",
    "    ax.set_title('%s - %d' %(State,year), {\n",
    "        'fontsize': font_size,\n",
    "        'fontweight' : 'bold',\n",
    "        'verticalalignment': 'top'\n",
    "        })\n",
    "    \n",
    "    ax.view_init(elev=40)\n",
    "    ax.dist = 13\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     plt.show()\n",
    "    plt.savefig(\n",
    "        \"c:\\\\Nextcloud\\\\Thermal Battery Research\\\\Publications\\\\paper_1\\\\pictures\\\\\"+\n",
    "        \"RRP annual\\\\Surfplots\\\\RRP_surf_%s_Year_%d.png\" %(State,year), dpi=600)\n",
    "    plt.savefig(\n",
    "        \"c:\\\\Nextcloud\\\\Thermal Battery Research\\\\Publications\\\\paper_1\\\\pictures\\\\\"+\n",
    "        \"RRP annual\\\\Surfplots\\\\RRP_surf_%s_Year_%d.eps\"%(State,year))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "print(\"Operating system: %s\" %sys.platform)\n",
    "if sys.platform == 'win32':\n",
    "    curr_path = 'c:\\\\Nextcloud\\\\Thermal Battery Research\\\\modelling\\\\python'\n",
    "elif sys.platform == 'linux':\n",
    "    curr_path = '/home/jeff/cloud/documents/work/ANU/Thermal Battery Research/modelling/python'\n",
    "else: print(\"What operating system are you running?! I've never even heard of %s\" %sys.platform)\n",
    "if curr_path not in sys.path:\n",
    "    sys.path.append(curr_path)\n",
    "    print('Path added! \\n')\n",
    "os.chdir(curr_path)\n",
    "print(\"Working directory is now %s\" %curr_path)\n",
    "\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import cm, dates\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import package.get_NEM_data as gd\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "# choose the state and date here\n",
    "State='SA'\n",
    "font_size = 14\n",
    "Years = np.arange(2010,2019,1)\n",
    "fig = plt.figure(figsize=(8,20))\n",
    "\n",
    "for i,year in enumerate(Years):\n",
    "    \n",
    "    ax = fig.add_subplot(len(Years)*100+10+(i+1))\n",
    "    \n",
    "#     plt.xscale('log')\n",
    "\n",
    "    price_spot=pd.DataFrame(gd.load_rrp_cal_stamped(year, State))\n",
    "    price_spot.columns = ['region', 'date_time', 'spot_price'] # define the data columns \n",
    "\n",
    "    plt.hist(price_spot['spot_price'],bins=100,\n",
    "         range=[-50,300], edgecolor='k', color='y', label=str(year))\n",
    "    if i==0:\n",
    "        plt.title('Region=%s' %(State), fontsize= font_size)\n",
    "        \n",
    "    plt.rc('ytick', labelsize=font_size)\n",
    "    plt.rc('xtick', labelsize=font_size)\n",
    "    plt.grid(which='both', axis='both')\n",
    "    plt.legend(loc='upper right', fontsize=font_size)\n",
    "    plt.ylabel('Frequency', fontsize= font_size)\n",
    "    ax.set_axisbelow(True)\n",
    "plt.xlabel('Spot price [AUD/MWh]', fontsize= font_size)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.savefig(\n",
    "# 'c:\\\\Nextcloud\\\\Thermal Battery Research\\\\Publications\\\\paper_1\\\\pictures\\\\RRP annual\\\\Histograms\\\\%s (Year %d)_Hist.png' %(State,year), dpi = 600)\n",
    "# plt.savefig(\n",
    "# 'c:\\\\Nextcloud\\\\Thermal Battery Research\\\\Publications\\\\paper_1\\\\pictures\\\\RRP annual\\\\Histograms\\\\%s (Year %d)_Hist.eps' %(State,year))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphically compare the forecast and predispatch prices\n",
    "In this code, you need to choose the state and the date to see the results.<br>\n",
    "Forecast prices are read from ```predispatch.db``` <br>\n",
    "Actual prices are read from ```spot_price.db``` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import datetime, pdb, sqlite3\n",
    "from projdirs import datadir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import cm, dates\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import package.get_NEM_data as gd\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# choose the state and date here\n",
    "State = 'VIC'\n",
    "state = \"'\" + State + \"'\"\n",
    "date = pd.to_datetime('2009/03/02 00:00:00')\n",
    "\n",
    "# connect to spot price database and load the data\n",
    "price_spot = gd.load_rrp_actual(date, State)\n",
    "\n",
    "# Load the forecast data\n",
    "price_pre = gd.load_rrp_forecast(date, State)\n",
    "\n",
    "\n",
    "# calculate the mean squared error\n",
    "# pdb.set_trace()\n",
    "Slice_pre = price_pre.loc[date: date+timedelta(days=1)]\n",
    "Slice_spot = price_spot.loc[date: date+timedelta(days=1)]\n",
    "error = np.array(Slice_pre['forecast_price'])-np.array(Slice_spot['spot_price'])\n",
    "MSE = np.sqrt(np.square(error).mean())\n",
    "\n",
    "# start plotting the data in one figure\n",
    "ax = Slice_spot.reset_index().plot(kind='line', x='date_time', y='spot_price', figsize=(10,5))\n",
    "Slice_pre.reset_index().plot(ax=ax, kind='line', x='date_time', y='forecast_price')\n",
    "ax.set_ylabel(\"Price ($/MWh)\")\n",
    "ax.set_title('State=%s, year=%s , MSE=%d, max. Error=%d'% (State,date.date(), MSE, np.max(error)));\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Mean Average Scaled Error (MASE) of forecast prices\n",
    "This code calulates the MASE for the forecast prices that are generated at different hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "print(\"Operating system: %s\" %sys.platform)\n",
    "if sys.platform == 'win32':\n",
    "    curr_path = 'd:\\\\Nextcloud\\\\Thermal Battery Research\\\\modelling\\\\python'\n",
    "elif sys.platform == 'linux':\n",
    "    curr_path = '/home/jeff/cloud/documents/work/ANU/Thermal Battery Research/modelling/python'\n",
    "else: print(\"What operating system are you running?! I've never even heard of %s\" %sys.platform)\n",
    "if curr_path not in sys.path:\n",
    "    sys.path.append(curr_path)\n",
    "    print('Path added! \\n')\n",
    "os.chdir(curr_path)\n",
    "print(\"Working directory is now %s\" %curr_path)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from projdirs import datadir, figdir, resultsdir, paperdir\n",
    "import matplotlib.pyplot as plt\n",
    "import package.sql_manager as sm\n",
    "from datetime import timedelta, time, date\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import package.storage_analysis as sa\n",
    "import package.get_NEM_data as gd\n",
    "from calendar import monthrange\n",
    "\n",
    "# MASE = sa.MASE('SA',2018, 300)\n",
    "\n",
    "import multiprocessing as mp\n",
    "from package.storage_analysis import MASE\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "print('Started!')\n",
    "output = [pool.apply_async(MASE, args=(State, Year, Cap))\n",
    "          for State in ['SA', 'NSW']\n",
    "          for Cap in [100]\n",
    "          for Year in np.arange(2010,2019,1) ]             \n",
    "pool.close()\n",
    "print('Completed!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "month_abre = [date(2018, i, 1).strftime('%b') for i in np.arange(1,13,1)]\n",
    "MASE_data = pd.DataFrame(columns=['state','year', 'cap', 'hour']+month_abre)\n",
    "db = 'MASE.db'\n",
    "table = 'MASE'\n",
    "cols = MASE_data.columns.tolist()\n",
    "idx_cols = cols[0:4]\n",
    "\n",
    "for r in output:\n",
    "    data = r.get()\n",
    "    sm.replace_into_db(data, db, table, cols, idx_cols=idx_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find a list of the days with very high spot prices\n",
    "First select the state <br>\n",
    "You can also choose a certain year in the last line of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# choose the state here\n",
    "state = \"'\" + 'VIC' + \"'\"\n",
    "\n",
    "#connect to the database that stores the capped storage values\n",
    "connection = sqlite3.connect(datadir + 'arbitrage\\\\' + 'spot_price.db')\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('SELECT date, time, price FROM actual_price WHERE state =' + state)\n",
    "\n",
    "data = pd.DataFrame([row for row in cursor.fetchall()])\n",
    "if data.empty:\n",
    "    print('data is not available!')\n",
    "else:\n",
    "    data.columns = ['date', 'time', 'price']\n",
    "    price = data\n",
    "    price['date_time'] = pd.to_datetime(price['date'] + ' ' +price['time'])\n",
    "\n",
    "# this line finds the days in the slected year on which the actual price was above a certain value\n",
    "price[(price['date_time']>'2019-01-01 00:00:00') & (price['price']>1000)]['date']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot mean squared error for the whole year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# choose the state and date here\n",
    "state = \"'\" + 'VIC' + \"'\"\n",
    "year = 2018\n",
    "# connect to spot price database and load the data\n",
    "connection = sqlite3.connect(datadir + 'arbitrage\\\\' + 'spot_price.db')\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('SELECT state, date, time, price FROM actual_price WHERE state =' + state )\n",
    "price_spot = pd.DataFrame([row for row in cursor.fetchall()])\n",
    "\n",
    "price_spot.columns = ['index', 'date', 'time', 'spot_price'] # define the data columns \n",
    "price_spot['date_time'] = pd.to_datetime(price_spot['date']+' '+price_spot['time'])#make a timestamp with the data\n",
    "connection.close\n",
    "price_spot = price_spot[(price_spot['date_time']>'2018-08-06 00:00:00') &  (price_spot['date_time']<'2019-08-30 00:00:00')];\n",
    "\n",
    "# connect to the predispatch database and load the forecast data\n",
    "connection = sqlite3.connect(datadir + 'arbitrage\\\\' + 'predispatch.db')\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('SELECT state, date, time, price FROM forecast_price WHERE state =' + state)\n",
    "price_pre = pd.DataFrame([row for row in cursor.fetchall()])\n",
    "price_pre.columns = ['index', 'date', 'time', 'forecast_price']# define the columns of data\n",
    "price_pre['date_time'] = pd.to_datetime(price_pre['date'] + ' ' +price_pre['time'])# define a timestamp column from the data\n",
    "connection.close\n",
    "price_pre = price_pre[(price_pre['date_time']>'2018-08-06 00:00:00') &  (price_pre['date_time']<'2019-08-30 00:00:00')];\n",
    "\n",
    "\n",
    "# calculate the mean squared error\n",
    "error = np.array(price_pre['forecast_price'])-np.array(price_spot['spot_price']);\n",
    "error_percent = (np.array(price_pre['forecast_price'])-np.array(price_spot['spot_price']))/np.array(price_spot['spot_price'])*100;\n",
    "# MSE = np.sqrt(np.square(error).mean())\n",
    "\n",
    "# start plotting the data in one figure\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.plot( price_pre['date_time'] , error)\n",
    "plt.title(' Error (State=%s, Year=%s-%s)'% (state, str(year), str(year+1)) )\n",
    "ax.grid()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.hist(error[np.logical_and(error>-200,error<200)], bins=500, color='r');\n",
    "plt.title(' Error distribution (State=%s, Year=%s-%s)'% (state, str(year), str(year+1)) )\n",
    "plt.xlabel('Error (Forecast - Actual) [$/MWh]')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.hist(error_percent[np.logical_and(error_percent>-200,error_percent<200)], bins=500, color='r');\n",
    "plt.title(' Percentage error distribution (State=%s, Year=%s-%s)'% (state, str(year), str(year+1)) );\n",
    "plt.xlabel('Percentage Error (Error/Actual) [%]')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot region price vs NEM total demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import scipy.optimize\n",
    "import sqlite3\n",
    "from projdirs import datadir\n",
    "%matplotlib inline\n",
    "# choose the state and date here\n",
    "region = 'NSW'\n",
    "states = ['QLD', 'TAS', 'VIC', 'SA', 'NSW']\n",
    "\n",
    "# connect to spot price database and load the data\n",
    "connection = sqlite3.connect(datadir + 'arbitrage\\\\' + 'demand_price.db')\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' \")\n",
    "print(cursor.fetchall())\n",
    "NEM_demand=pd.DataFrame()\n",
    "# NEM_demand.columns=['demand']\n",
    "for st in states:\n",
    "    state = \"'\" + st + \"'\"\n",
    "    cursor.execute('SELECT date, time, demand, price FROM demand_price WHERE state =' + state )\n",
    "    price = pd.DataFrame([row for row in cursor.fetchall()])\n",
    "    price.columns = ['date', 'time', 'demand', 'price'] # define the data columns \n",
    "    price['date_time'] = pd.to_datetime(price['date']+' '+price['time'])#make a timestamp with the data\n",
    "    price.set_index('date_time', inplace=True)\n",
    "    NEM_demand[st+' demand']=price['demand']\n",
    "    NEM_demand.set_index(price.index)\n",
    "    if region==st:\n",
    "        NEM_demand[region+' RRP']=price['price']\n",
    "    \n",
    "connection.close\n",
    "Date = datetime.strptime('2018-04-01', '%Y-%m-%d')\n",
    "TimeDelta = 14\n",
    "NEM_demand['total demand'] = NEM_demand.sum(axis=1)-NEM_demand[region+' RRP']\n",
    "ax = NEM_demand.loc[Date : Date+timedelta(days=TimeDelta)].plot.scatter(\n",
    "    x='total demand', y=region+' RRP', s=10, ylim=[0,100], figsize=(10,7.5), marker='o')\n",
    "ax.set_xlabel('Total NEM demand (MW)')\n",
    "ax.set_ylabel(region+' RRP (AUD/MWh)')\n",
    "ax.grid()\n",
    "ax.set_title(Date.strftime('%Y-%m-%d')+ ' until '+(Date+timedelta(days=TimeDelta)).strftime('%Y-%m-%d')+' (%s)'% (st) )\n",
    "# def func(x,a,b,c,d):\n",
    "#     return a*x+b\n",
    "# #     return a*x**3+b*x**2+c*x+d\n",
    "# #     return a*np.exp(-b*x)+c\n",
    "\n",
    "# x = np.array(NEM_demand['total demand'])\n",
    "# y = np.array(NEM_demand[region+' RRP'])\n",
    "\n",
    "# popt, pcov = scipy.optimize.curve_fit(func, x, y)\n",
    "# ax.plot(x, func(x, *popt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read FCAS data from the ```FCAS.db```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from projdirs import datadir\n",
    "import numpy as np\n",
    "from calendar import monthrange\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "# choose the state here\n",
    "state = \"'\" + '*' + \"'\"\n",
    "\n",
    "#connect to the database that stores the capped storage values\n",
    "connection = sqlite3.connect(datadir + 'arbitrage\\\\' + 'FCAS.db')\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('SELECT * FROM FCAS_prices')# WHERE REGIONID =' + state)\n",
    "\n",
    "data = pd.DataFrame([row for row in cursor.fetchall()])\n",
    "if data.empty:\n",
    "    print('data is not available!')\n",
    "else:\n",
    "    data.drop(0, axis=1, inplace=True)\n",
    "    data.columns = ['date_time', 'region', 'rrp', 'raise_6sec_rrp','raise_60sec_rrp','raise_5min_rrp','raise_reg_rrp',\n",
    "                    'lower_6sec_rrp','lower_60sec_rrp','lower_5min_rrp','lower_reg_rrp']\n",
    "    data[list(data.columns)[2:]] = data[data.applymap(np.isreal)][list(data.columns)[2:]].fillna(0)\n",
    "    data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "    fcas_prices = data\n",
    "\n",
    "    \n",
    "cursor.execute('SELECT * FROM FCAS_dispatch')# WHERE REGIONID =' + state)\n",
    "\n",
    "data = pd.DataFrame([row for row in cursor.fetchall()])\n",
    "if data.empty:\n",
    "    print('data is not available!')\n",
    "else:\n",
    "    data.drop(0, axis=1, inplace=True)\n",
    "    data.columns = ['date_time', 'region', 'total_demand', 'lower_5min_disp', 'lower_60sec_disp', 'lower_6sec_disp',\n",
    "                    'raise_5min_disp','raise_60sec_disp', 'raise_6sec_disp', 'lower_reg_disp', 'raise_reg_disp']\n",
    "    data[list(data.columns)[2:]] = data[data.applymap(np.isreal)][list(data.columns)[2:]].fillna(0)\n",
    "    data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "    fcas_dispatch = data.drop_duplicates(keep=False)\n",
    "\n",
    "    \n",
    "# plotting starts here    \n",
    "Global = False\n",
    "\n",
    "# if Global:\n",
    "#     def f(x,y):\n",
    "#         return np.array(fcas_dispatch.set_index('date_time').loc[pd.to_datetime(datetime.combine(x, y))]['total_demand'])\n",
    "        \n",
    "#     def ff(x):\n",
    "#         return x.hour*60+x.minute\n",
    "\n",
    "#     x1 = pd.date_range(fcas_dispatch['date_time'].dt.date.unique().min()+timedelta(days=1),\n",
    "#                        fcas_dispatch['date_time'].dt.date.unique().max()-timedelta(days=1), freq='10D').date\n",
    "#     y1 = pd.date_range('00:30:00','23:30:00', freq='30min').time\n",
    "#     x2, y2 = np.meshgrid(x1,y1)\n",
    "#     fig = plt.figure(figsize=(20,10))\n",
    "#     ax = fig.gca(projection='3d')\n",
    "#     g = np.vectorize(f)\n",
    "#     gg = np.vectorize(ff)\n",
    "#     z = g(x2,y2)\n",
    "#     z[z<-200]=-200\n",
    "#     z[z>200]=200\n",
    "#     surf = ax.plot_surface(matplotlib.dates.date2num(x2), gg(y2), z, rstride=1, cstride = 1, linewidth=1)\n",
    "#     ax.set_zlim(-200, 250)\n",
    "    # ax.set_xlim(737150, 737200)\n",
    "#     plt.show()\n",
    "        \n",
    "# else:\n",
    "#     TimeDelta = 0.5\n",
    "#     Date = datetime.strptime('2018-09-14', '%Y-%m-%d')\n",
    "#     Slice = fcas_prices.set_index('date_time').loc[Date : Date+timedelta(days=TimeDelta)]    \n",
    "#     ax = Slice.reset_index().plot(kind='line',x = 'date_time', y='rrp', figsize=(15,10), ylim = [0,200])\n",
    "#     Slice.reset_index().plot(ax=ax, kind='line', x='date_time', y='raise_6sec_rrp')\n",
    "#     Slice.reset_index().plot(ax=ax, kind='line', x='date_time', y='raise_60sec_rrp')\n",
    "#     Slice.reset_index().plot(ax=ax, kind='line', x='date_time', y='raise_5min_rrp')\n",
    "#     Slice.reset_index().plot(ax=ax, kind='line', x='date_time', y='raise_reg_rrp')\n",
    "#     Slice.reset_index().plot(ax=ax, kind='line', x='date_time', y='lower_6sec_rrp')\n",
    "#     Slice.reset_index().plot(ax=ax, kind='line', x='date_time', y='lower_60sec_rrp')\n",
    "#     Slice.reset_index().plot(ax=ax, kind='line', x='date_time', y='lower_5min_rrp')\n",
    "#     Slice.reset_index().plot(ax=ax, kind='line', x='date_time', y='lower_reg_rrp')\n",
    "#     ax.set_ylabel(\"Price ($/MWh)\")\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.hist(fcas_prices['rrp'],bins=100, range=[-1000,1000]);\n",
    "connection.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# fcas_prices.set_index('date_time', inplace=True)\n",
    "# fcas_dispatch.set_index('date_time', inplace=True)\n",
    "\n",
    "# cols = fcas_prices.columns.tolist()\n",
    "\n",
    "data = pd.concat([fcas_prices[['region', 'rrp', 'raise_reg_rrp']], fcas_dispatch['raise_reg_disp']],axis=1)\n",
    "\n",
    "indices = data[(data['raise_reg_rrp']>data['rrp']) & (data['raise_reg_disp']>0)].index.tolist()\n",
    "\n",
    "# data = fcas_prices.loc[indices][['region', 'rrp', 'raise_reg_rrp']]\n",
    "# data['raise_reg_disp'] = fcas_dispatch.loc[indices]['raise_reg_disp']\n",
    "# data['raise_reg_disp']*data['raise_reg_rrp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fcas_market = pd.DataFrame()\n",
    "dt = 0.5 #hr\n",
    "fcas_market.loc[0,'Rgulation_Raise'] = (fcas_prices['raise_reg_rrp']*fcas_dispatch['raise_reg_disp']*dt).sum()\n",
    "fcas_market['Fast_Raise'] = (fcas_prices['raise_6sec_rrp']*fcas_dispatch['raise_6sec_disp']*dt).sum()\n",
    "fcas_market['Slow_Raise'] = (fcas_prices['raise_60sec_rrp']*fcas_dispatch['raise_60sec_disp']*dt).sum()\n",
    "fcas_market['Delayed_Raise'] = (fcas_prices['raise_5min_rrp']*fcas_dispatch['raise_5min_disp']*dt).sum()\n",
    "\n",
    "fcas_market['Rgulation_Lower'] = (fcas_prices['lower_reg_rrp']*fcas_dispatch['lower_reg_disp']*dt).sum()\n",
    "fcas_market['Fast_Lower'] = (fcas_prices['lower_6sec_rrp']*fcas_dispatch['lower_6sec_disp']*dt).sum()\n",
    "fcas_market['Slow_Lower'] = (fcas_prices['lower_60sec_rrp']*fcas_dispatch['lower_60sec_disp']*dt).sum()\n",
    "fcas_market['Delayed_Lower'] = (fcas_prices['lower_5min_rrp']*fcas_dispatch['lower_5min_disp']*dt).sum()\n",
    "print(fcas_market/1000000) #market value in m$\n",
    "fcas_market.T.plot(kind='pie', subplots=True, figsize=(7.5,7.5), autopct='%.1f%%', legend=False, startangle = 30);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from package import get_NEM_data as gd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.concat([gd.load_fcas_rrp(2019,'NSW', 'lower_reg'), gd.load_fcas_rrp(2019,'NSW', 'raise_reg')], axis=1)\n",
    "# df['raise_reg'] = gd.load_fcas_rrp(2019,'NSW', 'raise_reg')\n",
    "ax = df.reset_index().loc[0:1000].plot(x='date_time', y='lower_reg_rrp', color='r')\n",
    "df.reset_index().loc[0:1000].plot(x='date_time', y='raise_reg_rrp', color = 'g', ax=ax)\n",
    "ax.set_ylim([-10,50])\n",
    "# fcas_disp = list(gd.load_fcas_disp(year_range[j],states[i], fcas_market))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
